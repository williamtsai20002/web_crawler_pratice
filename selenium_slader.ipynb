{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendant = \"https://www.slader.com\"\n",
    "chrome_path = \"/Users/DCT/Desktop/chromedriver_win32/chromedriver\"\n",
    "file_path = \"C:/Users/DCT/Desktop/slader_textbook\"\n",
    "book_list = [\"algorithm\",\"calculus\"] # store book name\n",
    "book_url = [] #stor book url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "import urllib.request\n",
    "\n",
    "def download_img(dir_path, name, url):\n",
    "    try:\n",
    "        if not os.path.exists(dir_path): # make the file if not exist\n",
    "            os.makedirs(dir_path)\n",
    "        #suffix = \".\" + url.split(\".\")[-1]\n",
    "        suffix = \".jpg\"\n",
    "        file_name = \"{}{}{}{}\".format(dir_path, os.sep, name, suffix)\n",
    "        urllib.request.urlretrieve(url, file_name)\n",
    "        #print(file_name)\n",
    "        return True\n",
    "    except:\n",
    "        print(\"download_img error, dir_path : \", dir_path)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = webdriver.Chrome(chrome_path)\n",
    "wd.get(pendant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = wd.find_element_by_link_text(\"SEARCH\")\n",
    "event.click()\n",
    "blank_search = wd.find_elements_by_name(\"search_query\")\n",
    "# blank_search[1] and blank_search[2] is interactable\n",
    "\n",
    "blank_search[1].send_keys(\"\") # test whether ele is interactable\n",
    "blank_search[1].send_keys(Keys.RETURN) # go to https://www.slader.com/search/?search_query=\n",
    "\n",
    "search_ele = wd.find_element_by_id(\"search-input\") # find the search column\n",
    "for book in book_list:\n",
    "    search_ele.clear()\n",
    "    search_ele.send_keys(book)\n",
    "    time.sleep(1) # wait html change after send_keys\n",
    "    soup = bs(search_ele.find_element_by_xpath(\"//body\").get_attribute('outerHTML'))\n",
    "    \n",
    "    # get all books relative to keywords in book_list\n",
    "    for ele in soup.select(\".textbook-work-index-widget\"):\n",
    "        book_url.append(pendant + ele[\"data-url\"])\n",
    "    if len(book_url) == 0:\n",
    "        print(\"did not get any url, please check your keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in book_url:\n",
    "    wd.get(ele)\n",
    "    time.sleep(1)\n",
    "    page_input = wd.find_element_by_xpath(\"//form[@class='textbook-page-search']/input[1]\") # find page input column\n",
    "    \n",
    "    # go to the first page\n",
    "    page_input.send_keys(\"1\") \n",
    "    page_input.send_keys(Keys.RETURN)\n",
    "    \n",
    "    # use request to get first_page (faster than selenium)\n",
    "    first_page_url = wd.current_url\n",
    "    try:\n",
    "        first_page_content = requests.get(first_page_url)\n",
    "    except:\n",
    "        print(\"requests error in : \" + first_page_url)\n",
    "    first_page_soup = bs(first_page_content.text, \"html.parser\")\n",
    "    \n",
    "    # find name of this book\n",
    "    book_name = first_page_soup.find(\"a\", {\"class\":\"textbook desktop\"}).get_text().strip()\n",
    "    ISBN = first_page_soup.find(\"section\", {\"class\":\"bottom-row\"}).get_text().strip().replace(\" \",\"\").replace(\":\",\"\").replace(\"/\",\"_\")\n",
    "    print(book_name,\" \",ISBN)\n",
    "    \n",
    "    # find all pages have excercises in first page\n",
    "    section_menu = first_page_soup.find_all(\"option\",{\"class\":\"section-menu-item\"})\n",
    "    \n",
    "    # request all pages (include first page)\n",
    "    for page_data in section_menu:\n",
    "        page_url = pendant + page_data[\"data-url\"] # this page url\n",
    "        try:\n",
    "            page_content = requests.get(page_url)\n",
    "        except:\n",
    "            print(\"requests error in : \" + page_url)\n",
    "        page_soup = bs(page_content.text, \"html.parser\")\n",
    "        excercise = page_soup.find_all(\"div\",{\"class\":\"list-item unbound exercise-in-group-item\"}) # excercise in this page\n",
    "        \n",
    "        # find_page_num\n",
    "        page_num = \"page_\" + page_soup.select(\".textbook-page-search input\")[0][\"value\"]\n",
    "        \n",
    "        # handle all excercises in this page\n",
    "        for ex_url in excercise:\n",
    "            wd.get(pendant + ex_url[\"data-url\"]) # use selenium to go to each excercise\n",
    "            time.sleep(1)\n",
    "            \n",
    "            ex_soup = bs(wd.page_source)\n",
    "            ex_str = ex_soup.find_all(\"a\", {\"class\":\"bc\"})[-1].get_text().strip().replace(\" \", \"\")\n",
    "            \n",
    "            # get img of excercise and download it\n",
    "            img_num = 0\n",
    "            for ele in ex_soup.select(\".solution-content img\"):\n",
    "                img_url = ele[\"src\"]\n",
    "                img_name = book_name + \"_\" + ex_str + str(img_num)\n",
    "                store_path = \"{}{}{}{}{}{}{}{}\".format(file_path, os.sep, book_name, ISBN, os.sep, page_num, os.sep, ex_str)\n",
    "                check = download_img(store_path, img_name, img_url)\n",
    "                if check:\n",
    "                    img_num += 1\n",
    "            \n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
